{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "julia-1.3",
      "display_name": "Julia 1.3"
    },
    "accelerator": "GPU",
    "colab": {
      "name": "Lab4_Merve.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrvoral/Comp541-Project/blob/master/Lab4_Merve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7S9cpFJqfXy",
        "colab_type": "text"
      },
      "source": [
        "## Julia on Colaboratory ##\n",
        "\n",
        "[Colaboratory](https://colab.research.google.com) does not provide native support for the [Julia programming language](https://julialang.org). However, since Colaboratory gives you root access to the machine that runs your notebook (the *“runtime”* in Colaboratory terminology), we can install Julia support by uploading a specially crafted Julia notebook  – *this* notebook. We then install Julia and [IJulia](https://github.com/JuliaLang/IJulia.jl) ([Jupyter](https://jupyter.org)/Colaboratory notebook support) and reload the notebook so that Colaboratory detects and initiates what we installed.\n",
        "\n",
        "In brief:\n",
        "\n",
        "1. **Run the cell below**\n",
        "2. **Reload the page**\n",
        "3. **Edit the notebook name and start hacking Julia code below**\n",
        "\n",
        "**If your runtime resets**, either manually or if left idle for some time, **repeat steps 1 and 2**.\n",
        "\n",
        "### Acknowledgements ###\n",
        "\n",
        "This hack by Pontus Stenetorp is an adaptation of [James Bradbury’s original Colaboratory Julia hack](https://discourse.julialang.org/t/julia-on-google-colab-free-gpu-accelerated-shareable-notebooks/15319/27), that broke some time in September 2019 as Colaboratory increased their level of notebook runtime isolation. There also appears to be CUDA compilation support installed by default for each notebook runtime type in October 2019, which shaves off a good 15 minutes or so from the original hack’s installation time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrHjOFFsxf7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installation cell\n",
        "%%shell\n",
        "if ! command -v julia 2>&1 > /dev/null\n",
        "then\n",
        "    wget 'https://julialang-s3.julialang.org/bin/linux/x64/1.3/julia-1.3.1-linux-x86_64.tar.gz' \\\n",
        "        -O /tmp/julia.tar.gz\n",
        "    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "    rm /tmp/julia.tar.gz\n",
        "fi\n",
        "julia -e 'using Pkg; pkg\"add Plots; add PyPlot; add IJulia; add Knet;\"'\n",
        "julia -e 'using Pkg; pkg\"build Knet;\"'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWDXteAbeUmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "32c302b3-1e7f-4461-a44f-9976cac06f93"
      },
      "source": [
        "using Knet: Knet, conv4, pool, mat, KnetArray, nll, zeroone, progress, sgd, param, param0, dropout, relu, Data, gpu, softmax\n",
        "Knet.gpu()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┌ Warning: You are using CUDNN 7.6.5 for CUDA 10.1.0 with CUDA toolkit 10.0.145; these might be incompatible.\n",
            "└ @ CuArrays /root/.julia/packages/CuArrays/1njKF/src/CuArrays.jl:122\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChU8ajWdguSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set display width, load packages, import symbols\n",
        "ENV[\"COLUMNS\"]=72\n",
        "using Pkg; for p in (\"Knet\",\"IterTools\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
        "using Knet, IterTools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUhJmLj8aOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Svokbdmc00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define convolutional layer:\n",
        "struct Conv; w; b; f; end\n",
        "(c::Conv)(x) = pool(c.f.(conv4(c.w, x;padding=0) .+ c.b),window=(2,2),stride=2)\n",
        "Conv(w1,w2,cx,cy,f=relu) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EixjlZ8mmdNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define dense layer:\n",
        "struct Dense; w; b; f; end\n",
        "(d::Dense)(x) = d.f.(d.w * mat(x) .+ d.b)\n",
        "Dense(i::Int,o::Int,f=sigm) = Dense(param(o,i), param0(o), f);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw1sFr-_mdU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a chain of layers:\n",
        "struct Chain; layers; Chain(args...)=new(args); end\n",
        "(c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
        "(c::Chain)(x,y) = nll(c(x),y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhMljQ8UmdXz",
        "colab_type": "code",
        "outputId": "9d6223b5-1b4a-4689-fe77-e9d0bf08ff94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load MNIST data\n",
        "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
        "dtrn, dtst = mnistdata();"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┌ Info: Loading MNIST...\n",
            "└ @ Main /root/.julia/packages/Knet/2xiR8/data/mnist.jl:33\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "entfERpdna2g",
        "colab_type": "code",
        "outputId": "ad92b7f2-014b-4571-f392-3528d9897ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Train and test LeNet (about 30 secs on a gpu to reach 99% accuracy)\n",
        "LeNet = Chain(Conv(5,5,1,3), Dense(12*12*3,10))\n",
        "progress!(adam(LeNet, ncycle(dtrn,100)))\n",
        "accuracy(LeNet, dtst)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┣████████████████████┫ [100.00%, 60000/60000, 01:55/01:55, 520.93i/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9876"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6-FfL-4q6op",
        "colab_type": "code",
        "outputId": "fc2e478a-9de3-4fd3-d64e-32748eb55a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train and test LeNet (about 30 secs on a gpu to reach 99% accuracy)\n",
        "D1=10\n",
        "LeNet = Chain(Conv(2,2,1,10), Conv(3,3,10,50),Conv(5,5,50,D1),Dense(D1,10))\n",
        "progress!(adam(LeNet, ncycle(dtrn,100)))\n",
        "1-accuracy(LeNet,dtrn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "┣███████████▌        ┫ [57.52%, 34513/60000, 01:53/03:17, 312.34i/s] "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UlmF6I0BaZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}